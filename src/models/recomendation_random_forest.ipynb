{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category Recomendation Random Forest\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import top_k_accuracy_score, label_ranking_average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path : str = \"./dataset/\"\n",
    "cities =  [\"Burgos\", \"León\", \"Palencia\", \"Salamanca\", \"Valladolid\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset(data_path: str) -> dict:\n",
    "\n",
    "    # Abrimos el fichero de datos y lo convertimos a un dataframe\n",
    "    with open(data_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "    # Contamos las apariciones de cada categoría\n",
    "    category_count = df['Categoria'].value_counts()\n",
    "\n",
    "    # Obtenemos dataframes para aquellas categorías con una única aparición\n",
    "    single_categories = df[df['Categoria'].isin(category_count[category_count == 1].index)]\n",
    "    single_categories_attr = single_categories.drop('Categoria', axis=1)\n",
    "    single_categories_y = single_categories['Categoria']\n",
    "\n",
    "    # Eliminamos las categorías con una única aparición del conjunto de datos\n",
    "    df = df.drop(single_categories.index)\n",
    "\n",
    "    # Separamos en dataframes de atributos y etiquetas\n",
    "    df_attr = df.drop('Categoria', axis=1)\n",
    "    df_y = df['Categoria']\n",
    "\n",
    "    dataset = {\n",
    "        \"single_categories_X\" : single_categories_attr,\n",
    "        \"single_categories_Y\" : single_categories_y,\n",
    "        \"X\" : df_attr,\n",
    "        \"Y\" : df_y\n",
    "    }\n",
    "\n",
    "    return dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(real_categories, category_probs, categories) -> float:\n",
    "    mrr: float = 0\n",
    "    sample_size = len(category_probs)\n",
    "\n",
    "    for real, probs in zip(real_categories, category_probs):\n",
    "        ranking: list = [[category, prob]\n",
    "                         for category, prob in zip(categories, probs)]\n",
    "        ranking.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        for index, prob in enumerate(ranking, start=1):\n",
    "            if prob[0] == real:\n",
    "                mrr += 1/index\n",
    "                break\n",
    "\n",
    "    return mrr/sample_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_random_forest(dataset, k=5, **kwargs):\n",
    "\n",
    "    # Creamos el objeto para KFold para hacer validación cruzada\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random.randint(0, 100))\n",
    "\n",
    "    # Dataframes de atributos y etiquetas\n",
    "    X = dataset[\"X\"]\n",
    "    Y = dataset[\"Y\"]\n",
    "\n",
    "    # Dataframes de categorías con una única aparición\n",
    "    single_categories_x = dataset[\"single_categories_X\"]\n",
    "    single_categories_y = dataset[\"single_categories_Y\"]\n",
    "\n",
    "    folds_mrr = []\n",
    "\n",
    "    if \"city\" in kwargs:\n",
    "        print(f\"[{kwargs['city']}]\")\n",
    "\n",
    "    for n_fold, (train, test) in enumerate(kf.split(X), start=1):\n",
    "        print(f\">>> Fold: {n_fold}\")\n",
    "        classifier = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "        fold_time = time.time()\n",
    "\n",
    "        # Añadimos al conjunto de datos de entrenamiento las categorías con una sola aparición\n",
    "        df_train_x = pd.concat([X.iloc[train], single_categories_x])\n",
    "        df_train_y = pd.concat([Y.iloc[train], single_categories_y])\n",
    "\n",
    "        # Definimos conjunto de test\n",
    "        df_test_x = X.iloc[test]\n",
    "        df_test_y = Y.iloc[test]\n",
    "\n",
    "        # Entrenamos el modelo\n",
    "        classifier.fit(df_train_x, df_train_y)\n",
    "\n",
    "        # Predicciones\n",
    "        preds = classifier.predict_proba(df_test_x)\n",
    "\n",
    "        # Calculamos el MRR\n",
    "        mrr = mean_reciprocal_rank(df_test_y, preds, classifier.classes_)\n",
    "        folds_mrr.append(mrr)\n",
    "        print(f\"> MRR: {mrr}\")\n",
    "        print(f\"> Tiempo fold {n_fold}: {time.time() - fold_time :.1f} s\")\n",
    "\n",
    "    return folds_mrr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Burgos]\n",
      ">>> Fold: 1\n",
      "> MRR: 0.279678304926792\n",
      "> Tiempo fold 1: 87.3 s\n",
      ">>> Fold: 2\n",
      "> MRR: 0.2805446374407585\n",
      "> Tiempo fold 2: 93.0 s\n",
      ">>> Fold: 3\n",
      "> MRR: 0.27692012011684014\n",
      "> Tiempo fold 3: 93.7 s\n",
      ">>> Fold: 4\n",
      "> MRR: 0.26977357818943204\n",
      "> Tiempo fold 4: 94.4 s\n",
      ">>> Fold: 5\n",
      "> MRR: 0.2728845555580882\n",
      "> Tiempo fold 5: 88.0 s\n",
      "[León]\n",
      ">>> Fold: 1\n",
      "> MRR: 0.3564057188871915\n",
      "> Tiempo fold 1: 4.8 s\n",
      ">>> Fold: 2\n",
      "> MRR: 0.38140156749338094\n",
      "> Tiempo fold 2: 4.9 s\n",
      ">>> Fold: 3\n",
      "> MRR: 0.3899625789896216\n",
      "> Tiempo fold 3: 5.0 s\n",
      ">>> Fold: 4\n",
      "> MRR: 0.4000012657797871\n",
      "> Tiempo fold 4: 5.0 s\n",
      ">>> Fold: 5\n",
      "> MRR: 0.4061514574549984\n",
      "> Tiempo fold 5: 5.1 s\n",
      "[Palencia]\n",
      ">>> Fold: 1\n",
      "> MRR: 0.33392707324976584\n",
      "> Tiempo fold 1: 8.7 s\n",
      ">>> Fold: 2\n",
      "> MRR: 0.28395809897386326\n",
      "> Tiempo fold 2: 8.7 s\n",
      ">>> Fold: 3\n",
      "> MRR: 0.3303125095811895\n",
      "> Tiempo fold 3: 8.8 s\n",
      ">>> Fold: 4\n",
      "> MRR: 0.24540892010671564\n",
      "> Tiempo fold 4: 8.3 s\n",
      ">>> Fold: 5\n",
      "> MRR: 0.2943554943506483\n",
      "> Tiempo fold 5: 8.4 s\n",
      "[Salamanca]\n",
      ">>> Fold: 1\n",
      "> MRR: 0.21770739048177007\n",
      "> Tiempo fold 1: 66.6 s\n",
      ">>> Fold: 2\n",
      "> MRR: 0.20649815349899797\n",
      "> Tiempo fold 2: 65.8 s\n",
      ">>> Fold: 3\n",
      "> MRR: 0.23980444837012208\n",
      "> Tiempo fold 3: 69.8 s\n",
      ">>> Fold: 4\n",
      "> MRR: 0.23098654261963217\n",
      "> Tiempo fold 4: 67.0 s\n",
      ">>> Fold: 5\n",
      "> MRR: 0.2258890863014458\n",
      "> Tiempo fold 5: 66.8 s\n",
      "[Valladolid]\n",
      ">>> Fold: 1\n",
      "> MRR: 0.2654275986984411\n",
      "> Tiempo fold 1: 54.7 s\n",
      ">>> Fold: 2\n",
      "> MRR: 0.28084926371310814\n",
      "> Tiempo fold 2: 53.7 s\n",
      ">>> Fold: 3\n",
      "> MRR: 0.2832005779476121\n",
      "> Tiempo fold 3: 54.4 s\n",
      ">>> Fold: 4\n",
      "> MRR: 0.27904205371053153\n",
      "> Tiempo fold 4: 56.0 s\n",
      ">>> Fold: 5\n",
      "> MRR: 0.26606873479004195\n",
      "> Tiempo fold 5: 53.7 s\n",
      "{'Burgos': [0.279678304926792, 0.2805446374407585, 0.27692012011684014, 0.26977357818943204, 0.2728845555580882], 'León': [0.3564057188871915, 0.38140156749338094, 0.3899625789896216, 0.4000012657797871, 0.4061514574549984], 'Palencia': [0.33392707324976584, 0.28395809897386326, 0.3303125095811895, 0.24540892010671564, 0.2943554943506483], 'Salamanca': [0.21770739048177007, 0.20649815349899797, 0.23980444837012208, 0.23098654261963217, 0.2258890863014458], 'Valladolid': [0.2654275986984411, 0.28084926371310814, 0.2832005779476121, 0.27904205371053153, 0.26606873479004195]}\n"
     ]
    }
   ],
   "source": [
    "cities_mrr = dict()\n",
    "\n",
    "for city in cities:\n",
    "    dataset = construct_dataset(f\"{data_path}Q_{city}.json\")\n",
    "    cities_mrr[city] = cross_validate_random_forest(dataset, city=city, k=5)\n",
    "\n",
    "print(cities_mrr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./MRR.json\", \"r\", encoding=\"utf-8\") as read_json,  open(\"./CompleteMRR.json\", \"w\", encoding=\"utf-8\") as write_json:\n",
    "    other_mrr = json.load(read_json)\n",
    "\n",
    "    for city in cities:\n",
    "        other_mrr[city][\"Qrandom_forest\"] = np.average(cities_mrr[city])\n",
    "\n",
    "    json.dump(other_mrr,write_json, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
